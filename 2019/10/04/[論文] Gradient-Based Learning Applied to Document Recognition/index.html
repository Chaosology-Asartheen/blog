<!DOCTYPE html>





<html lang="zh-TW">
<head>
  <meta name="google-site-verification" content="exmdvS3MT1hVojBxSEZZZ8TIBBOg6pJ2POTtzNuecqs" />
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">


<meta property="og:site_name" content="">
<meta property="og:title" content="categories">
<meta property="og:url" content="http://">
<meta property="og:image" content="">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/blog/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/blog/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Gemini',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","width":280,"display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '複製',
      copy_success: '複製成功',
      copy_failure: '複製失敗'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="前言機器學習或是深度學習，雖說發展已久，但在近幾年的發展突飛猛進，不管是 google , Facebook 還是 Amazon 的論文發表真的是一篇接著一篇，新技巧、新概念的開展著實讓人覺得不可思議，要了解整個發展以及新技術的應用，閱讀論文想必是最快速的方法。 在台灣 Pytorch Taiwan 以及許多讀書會也都開始有論文閱讀的部分都是正在進行式，我也是期待自己養成閱讀論文的習慣，因此便著手">
<meta property="og:type" content="article">
<meta property="og:title" content="[ 論文 ] Gradient-Based Learning Applied to Document Recognition">
<meta property="og:url" content="https://allen108108.github.io/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/index.html">
<meta property="og:site_name" content="Math.py">
<meta property="og:description" content="前言機器學習或是深度學習，雖說發展已久，但在近幾年的發展突飛猛進，不管是 google , Facebook 還是 Amazon 的論文發表真的是一篇接著一篇，新技巧、新概念的開展著實讓人覺得不可思議，要了解整個發展以及新技術的應用，閱讀論文想必是最快速的方法。 在台灣 Pytorch Taiwan 以及許多讀書會也都開始有論文閱讀的部分都是正在進行式，我也是期待自己養成閱讀論文的習慣，因此便著手">
<meta property="og:locale" content="zh-TW">
<meta property="og:image" content="https://i.imgur.com/BXEWBsY.png">
<meta property="og:image" content="https://i.imgur.com/WDxti0L.png">
<meta property="og:image" content="https://i.imgur.com/U1Qy4xM.png">
<meta property="og:image" content="https://i.imgur.com/kPUkWKL.png =250x">
<meta property="og:image" content="https://i.imgur.com/7tGTZHB.png =400x">
<meta property="og:image" content="https://i.imgur.com/XJ5yPms.jpg">
<meta property="og:image" content="https://i.imgur.com/zG8PMM3.png">
<meta property="og:image" content="https://i.imgur.com/o49ic8B.png">
<meta property="og:updated_time" content="2019-12-04T04:12:04.325Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[ 論文 ] Gradient-Based Learning Applied to Document Recognition">
<meta name="twitter:description" content="前言機器學習或是深度學習，雖說發展已久，但在近幾年的發展突飛猛進，不管是 google , Facebook 還是 Amazon 的論文發表真的是一篇接著一篇，新技巧、新概念的開展著實讓人覺得不可思議，要了解整個發展以及新技術的應用，閱讀論文想必是最快速的方法。 在台灣 Pytorch Taiwan 以及許多讀書會也都開始有論文閱讀的部分都是正在進行式，我也是期待自己養成閱讀論文的習慣，因此便著手">
<meta name="twitter:image" content="https://i.imgur.com/BXEWBsY.png">
  <link rel="canonical" href="https://allen108108.github.io/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>[ 論文 ] Gradient-Based Learning Applied to Document Recognition | Math.py</title>
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-149442581-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-149442581-1');
    }
  </script>








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-TW">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Math.py</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Wir müssen wissen , wir werden wissen</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切換導航欄">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/blog/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首頁</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/blog/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分類</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/blog/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>歸檔</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://allen108108.github.io/blog/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allen Tzeng">
      <meta itemprop="description" content="Study about Mathematics , Programming and Data Science">
      <meta itemprop="image" content="/blog/images/allen.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Math.py">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[ 論文 ] Gradient-Based Learning Applied to Document Recognition

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              
                
              

              <time title="創建時間：2019-10-04 02:14:02" itemprop="dateCreated datePublished" datetime="2019-10-04T02:14:02+08:00">2019-10-04</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2019-12-04 12:12:04" itemprop="dateModified" datetime="2019-12-04T12:12:04+08:00">2019-12-04</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/blog/categories/論文-Paper/" itemprop="url" rel="index"><span itemprop="name">論文 Paper</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="閱讀次數" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">閱讀次數：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>機器學習或是深度學習，雖說發展已久，但在近幾年的發展突飛猛進，不管是 google , Facebook 還是 Amazon 的論文發表真的是一篇接著一篇，新技巧、新概念的開展著實讓人覺得不可思議，要了解整個發展以及新技術的應用，閱讀論文想必是最快速的方法。</p>
<p>在台灣 Pytorch Taiwan 以及許多讀書會也都開始有論文閱讀的部分都是正在進行式，我也是期待自己養成閱讀論文的習慣，因此便著手第一篇論文的閱讀。</p>
<p>第一篇論文，就從這 Convolutional Neural Network 的發源論文 <em>“Gradient-Based Learning Applied to Document Recognition”</em> 作為起頭吧 ! 這篇論文介紹了經典模型 LeNet-5 進行手寫數字辨識，許多人都將此論文視為 CNN 的起源，雖然說此論文年代稍為久遠，與現今的 CNN 模型稍有不同，但仍可藉由此論文體會、了解 CNN 的架構及精神。</p>
<a id="more"></a>
<p>此論文內容非常充實，足足有46頁之多，本篇文章主要著重在論文兩個核心部分，分別是 Introduction 以及 Convolutional Neural Network for Isolated Character Recognition。</p>
<h2 id="論文摘要"><a href="#論文摘要" class="headerlink" title="論文摘要"></a>論文摘要</h2><h2 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I.  Introduction"></a>I.  Introduction</h2><p>本論文最重要的是建構了一個更自動化的學習機器來進行手寫辨識，而減少人為手把手設計的辨識系統。</p>
<p>過去的模型，在特徵萃取的技巧上，都被限制在低維度空間上進行操作才能有比較好的表現，但近幾年來卻能夠提升高維度空間上的表現，且可以處理相對大量的資料集，主要的原因有三 : </p>
<p>(1) 低價高效的計算單位容易取得，使得我們可以利用暴力的數值方法硬處理。<br>(2) 資料的取得更加容易，可以輕易地取得任何我們有興趣的資料。<br>(3) 最重要的一點是，機器學習技巧的發展，使我們可以在高維度上對大量的資料及進行處理。</p>
<h3 id="A-Learning-from-Data"><a href="#A-Learning-from-Data" class="headerlink" title="A. Learning from Data"></a>A. Learning from Data</h3><p>若我們手中有一組訓練資料 $\left\{(Z^1,D^1),(Z^2,D^2),\cdots,(Z^P,D^P)\right\}$，我們可以使用機器學習方式對所有的輸入資料 $Z^p$ 學習出一套模式、一組權重 $W$ ，進行預測得到 $Y^p$</p>
<script type="math/tex; mode=display">
Y^p=F(Z^p,W)</script><p>進而我們可以針對預測值 $Y^p$ 與真實值 $D^p$ 計算誤差 $E^p$，也可以計算出整個訓練資料集的平均誤差 $E_{train}$</p>
<script type="math/tex; mode=display">
E^p=D(D^p,Y^p)=D(D^p,F(Z^p,W))\\
E_{train}=\displaystyle{\frac{1}{P}\sum\limits_{p=1}^{P}E^p}</script><p>之後我們在針對測試資料上的誤差期望值 $E_{test}$ 與 $E_{train}$ 進行比較已確認模型的準確度。而在一些研究工作上顯示出此二者的誤差會接近 $k(h/P)^{\alpha}$，$P$ 為訓練資料的數量， $h$ 是模型複雜度， $\alpha$ 則是介於 0.5 到 1 的常數值，而 $k$ 亦為常數值。</p>
<script type="math/tex; mode=display">
E_{test}-E_{train}=k(h/P)^{\alpha}</script><h3 id="B-Gradient-Based-Learning"><a href="#B-Gradient-Based-Learning" class="headerlink" title="B. Gradient-Based Learning"></a>B. Gradient-Based Learning</h3><p>既然我們計算出對於任何一組權重 $W$ 資料所產生的誤差 $E(W)$ ，那我們便希望可以藉由調整權重 $W$，來讓誤差越來越小。而 Gradient-Based Learning 針對平滑可微分的連續函數提供了一個較為簡單的優化方式。</p>
<p>在 Gradient Descent 的方法中，我們不斷迭代調整 $W$，來得到更小的誤差值</p>
<script type="math/tex; mode=display">
W_k=W_{k-1}-\epsilon\displaystyle{\frac{\partial E(W)}{\partial W}}</script><p>而另一種更受歡迎的方法 : Stochastic Gradient Descent ( SGD ) ，改善 Gradient Descent 每一次都要丟全部的資料進去算梯度，SGD 利用隨機單筆資料的梯度拿來更新參數，就計算成本上來說會節省不少。</p>
<script type="math/tex; mode=display">
W_k=W_{k-1}-\epsilon\displaystyle{\frac{\partial E^{p_k}(W)}{\partial W}}</script><h3 id="C-Gradient-Back-Propagation"><a href="#C-Gradient-Back-Propagation" class="headerlink" title="C. Gradient Back-Propagation"></a>C. Gradient Back-Propagation</h3><p>在1950年代後期，Greadient-Based Learning 開始被人們使用，但也幾乎都僅限於線性系統。近年來幾件事情的發展使得 Gradient Descent 被廣泛的應用 : </p>
<ol>
<li>Loss function 的局部最小值並不會是實務上的主要問題 ( 李宏毅課程中也有講到，有些學者甚至認為高維度出現局部最小值的機率其實很小，我們使用 Gradient Descent 很可能找到的都是全局最小值。 )</li>
<li>Backpropagation (BP) algorithm 在多層非線性系統中可以有效率的計算梯度。</li>
<li>Backpropagation algorithm 也可以處理在多層神經網路中的複雜學習任務。</li>
</ol>
<p>BP 的核心概念就是從輸出層往前推導到輸入層，有效率的計算梯度，雖然在 60 年代初期就有類似的概念出現，但還沒應用在機器學習的問題中。</p>
<h3 id="D-Learning-in-Real-Handwriting-Recognition-Systems"><a href="#D-Learning-in-Real-Handwriting-Recognition-Systems" class="headerlink" title="D. Learning in Real Handwriting Recognition Systems"></a>D. Learning in Real Handwriting Recognition Systems</h3><p>( 略 )<br>手寫辨識中，最困難的並非辨識單獨的字母或數字，而是要對一整個句子或單字進行切割、分段。”Heuristic Over-segmentation” 便是處理這樣子問題的標準模式，它要能夠生成各種可能的切割方式，並從中找出最合適的組合。</p>
<p>而在此論文的後面幾個部分會提到如何實現 Segmentation ，但這不在本篇文章的討論範圍，因此不再贅述。</p>
<h3 id="E-Globally-Trainable-Systems"><a href="#E-Globally-Trainable-Systems" class="headerlink" title="E. Globally Trainable Systems"></a>E. Globally Trainable Systems</h3><p>( 略 )<br>這一個部分，主要在談一個完整辨識系統的各個模組是如何運作、如何互相串接，這部分也非本篇文章的討論範圍，因此也先不詳細介紹。</p>
<h2 id="II-Convolutional-Neural-Network-for-Isolated-Character-Recognition"><a href="#II-Convolutional-Neural-Network-for-Isolated-Character-Recognition" class="headerlink" title="II. Convolutional Neural Network for Isolated Character Recognition"></a>II. Convolutional Neural Network for Isolated Character Recognition</h2><p>傳統的辨識系統，利用人工定義的 feature extractor 取得相關聯的資訊並且去除不相關的變數，配合著全連接層神經網路分類器來進行分類。但我們更在意的是，是否能夠讓機器自己學習出一套 feature extractor，如此以來我們便可以直接餵原始資料進全連接層的分類器，直接進行辨識。</p>
<p>然而這樣會產生一些問題 : </p>
<ol>
<li>原始圖片的像素過大，在第一層的全連接層可能就會產生數以千萬計的參數(權重)，參數越多，我們就需要更多的訓練資料才能訓練出一個好的 model。當然，我們所需的計算成本也必須隨之增加。</li>
<li>一個非結構化的圖片、語音的問題就在於它們並沒有結構上的不變性，輸入分類器的型態可能千變萬化。以手寫文字來說，即使我們可以做一些前處理 —- 將圖片尺寸標準化、將手寫字置於圖片中央 —- 但不管怎麼做總是無法做的夠完美，手寫文字的大小不會固定、也有文字傾斜…等問題。理論上，只要我們提供足夠多的 neurons 應該也可以訓練得夠好，但仍會有計算成本及訓練樣本不夠多的狀況。</li>
<li>全連接層的架構忽略了圖片整體的拓樸性質，將輸入圖像轉化成為互相獨立的變數，但圖像本身具有很強的空間結構，某些像素跟周圍的像素間應該具有高度的相關性，這些相關聯的像素便組合成一個個局部特徵。而 CNN 便是掌握了這樣的概念進行有效的特徵萃取。</li>
</ol>
<h3 id="A-Convolutional-Network"><a href="#A-Convolutional-Network" class="headerlink" title="A. Convolutional Network"></a>A. Convolutional Network</h3><p>Convolutional Network 架構包含了三個重要的概念 : 局部感受野 (Local receptive fields )、權重共享 ( Shared weights ) 以及 子(二次)採樣 ( Sub-sampling )</p>
<p><strong>Local receptive fields</strong></p>
<p>局部感受野的概念在早期的醫學、生物學上面就有許多的研究，在這樣的局部館策中，視覺神經元可以直接萃取出圖像上的特徵 ( 如 : 邊緣、端點、角落…)，而這些特徵可以組合成夠高層次的特徵。而這些特徵仍然保有其拓樸性質。</p>
<p>而這樣特徵萃取的概念應用在 Neural Network 上便是利用一組 identical weight vector ( 在 CNN 中稱之為 kernel 或是 filter ) 掃過整張圖片，然後輸出一張 feature map。這樣的過程對應到論文中的 LeNet-5 模型即為 卷積層 ( Convolution Layer )。一個完整的卷積層會有多個 kernel ( weight vector ) 組成，然後轉出成若干個 feature maps。</p>
<p>之所以稱為卷積，主要是因為 kernel 利用滑動的方式掃過整張圖的每一個位置，並且記錄下每一個位置的狀態然後對應到 feature map 的相對位置，這樣的操作與數學上的 「卷積」 相同。<sup><a href="#fn_註1" id="reffn_註1">註1</a></sup></p>
<p>經過卷積層的操作後，一旦特徵被偵測出來後，這個特徵的精確位置便不是那麼重要，重要的反而是這個特徵與其他特徵的相對位置。</p>
<p><strong>Sub-sampling</strong></p>
<p>既然我們在意的是特徵間的相對位置，而不在意其精確的位置，最簡單的方式就是直接減少 feature map 的空間分辨率 ( Spatial Resolution )，做法便是將局部感受野進行平均化及子採樣，這過程便對應到 LeNet-5 的 Subsampling Layer ( 又稱作池化層 )。</p>
<p>在 LeNet-5 的 Subsampling Layer 中，利用 2X2 的 kernel，掃過 Convolution Layer 所產生的 feature maps，遍歷的方式與卷積層有所不同，每一個相鄰感受野均不重疊，將每一個局部區域數值取平均後再經過一個 sigmoid function 。經過 subsampling 過後的 feature maps 長寬均會減少一半。</p>
<p><strong>Shared weights</strong></p>
<p>由於卷積的操作特性，我們不難發現，每一個 kernel 滑過整張圖的過程中，參數都是固定的，這樣權重共享的概念讓我們在計算上減少非常多的負擔。而且也會使 test error 更接近 train error。</p>
<h3 id="B-LeNet-5"><a href="#B-LeNet-5" class="headerlink" title="B. LeNet-5"></a>B. LeNet-5</h3><p>這個部分主要再詳細介紹整個 LeNet-5 的各層架構及運作。$C$ 表示卷積層，$S$ 表示池化層，而 $F$ 則是全連接層，下標數字則是標示位於第幾層。由此可見，LeNet-5 是一個有六層主結構的辨識系統 ( 不含輸入輸出層 )。</p>
<p><img src="https://i.imgur.com/BXEWBsY.png" alt></p>
<p>以下我們依照各層分別介紹: </p>
<h4 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h4><p>LeNet-5的輸入格式為 $32\times 32$ 的手寫圖像。</p>
<h4 id="C-1-卷積層"><a href="#C-1-卷積層" class="headerlink" title="$C_1$ (卷積層)"></a>$C_1$ (卷積層)</h4><p>第一層是有 6 個 $5\times 5$ 的 kernel 的卷積層，每一個kernel經過卷積會輸出一張 feature map，因此在這一層會有六張 $28\times 28$ 的 feature maps。<br>( 以現在的 CNN 來說，這是 stride=1 且沒有 padding 的卷積層 )</p>
<p><img width="500" src="https://i.imgur.com/WDxti0L.png"><br>( 圖片來源 : <a href="https://www.charleychai.com/blogs/2018/ai/NN/lenet.html" target="_blank" rel="noopener">LeNet-5详解与实现</a> )</p>
<p>我們也可以輕易地計算，第一層一共有 $(25\times 6)+(1\times 6)=156$ 個權重，<br>及 $(25\times 28^2\times 6)+(28^2\times 6)=122304$ 個連結數。</p>
<h4 id="S-2-池化層"><a href="#S-2-池化層" class="headerlink" title="$S_2$ (池化層)"></a>$S_2$ (池化層)</h4><p>第二層是有 $2\times 2$ kernel 的池化層，先經過平均池化後給予一個權重及 偏置 ( bias ) 再丟進 sigmoid function 形成 feature maps。feature maps的尺寸經過池化後會減少一半 ( stride=2 )，亦即此層生成的 feature maps 尺寸會是 $14\times 14$。</p>
<p><img width="500" src="https://i.imgur.com/U1Qy4xM.png"><br>( 圖片來源 : <a href="https://www.charleychai.com/blogs/2018/ai/NN/lenet.html" target="_blank" rel="noopener">LeNet-5详解与实现</a> )</p>
<p>這一層一共有 $(1+1)\times 6=12$個權重，且有 $4\times 14^2\times 6+14^2\times 6=5880$ 個連結數。</p>
<h4 id="C-3-卷積層"><a href="#C-3-卷積層" class="headerlink" title="$C_3$ (卷積層)"></a>$C_3$ (卷積層)</h4><p>此層較為特別，作者採用的方式是將數個 $S_2$ 的 feature maps 一起做卷積，這樣會產生一共 16 個 feature maps，且每一個 feature map 大小為 $10\times 10$。( 連結方式如下圖右 )</p>
<p><img src="https://i.imgur.com/kPUkWKL.png =250x" alt>  <img src="https://i.imgur.com/7tGTZHB.png =400x" alt></p>
<p>為何不採用全連接的方式 ? 首先，這樣可以減少參數。其次，$C_3$ 每一個輸入的 feature map 都是 $C_1$ 的 kernel 針對輸入圖像所萃取出來的特徵圖，利用這樣不對稱的連結方式，反而可以組合成更高層級的特徵。 </p>
<p>這一層中我們有 $6\times(25\times 3+1)+9\times(4\times 25+1)+1\times(6\times 25+1)=1516$ 個參數及 $151600$ 個連結。</p>
<h4 id="S-4-池化層"><a href="#S-4-池化層" class="headerlink" title="$S_4$ (池化層)"></a>$S_4$ (池化層)</h4><p>操作方式與 $S_2$ 相同，經過 $2\times 2$ 的 kernel 池化過後，feature maps 的大小是 $5\times 5$。</p>
<p>此層具有 $(1+1)\times 16=32$個參數，及 $(4\times 25\times 16)+(25\times 16)=2000$ 個連結。</p>
<h4 id="C-5-卷積層"><a href="#C-5-卷積層" class="headerlink" title="$C_5$ (卷積層)"></a>$C_5$ (卷積層)</h4><p>這裡跟 $C_3$ 卷積層不同的地方在於這邊是採全連接的方式產出一共120個 feature maps，由 $5\times 5$ 的 kernel 一次對所有 ( 16個 ) $S_4$ 的 feature maps 卷積過後的 feature map 大小會變成 $1\times 1$。</p>
<p>這一層會有 $(5\times 5\times 16+1)\times 120=48120$ 個參數。</p>
<h4 id="F-6-全連接層"><a href="#F-6-全連接層" class="headerlink" title="$F_6$ (全連接層)"></a>$F_6$ (全連接層)</h4><p>這一層是一個簡單的全連接層，共有 84 個神經元，與上一層的 120 個 feature maps 進行全連接。( 為何取 84 ? 我們在 Output 層會說明。 )</p>
<p>如同一般的神經網路，這 84 個神經元都是 $C_5$ 層中 120 維向量與權重向量內積後，經過 activation function 轉換後再加上偏置而得。</p>
<p><img width="500" src="https://i.imgur.com/XJ5yPms.jpg"></p>
<p>因此這邊一共會有 $(120\times 84)+(1\times 84)=10164$ 個參數。</p>
<p>這裡使用的 activation function 是 $A\cdot tanh(Sa)$，其中 $S$ 是原點的斜率，則 $A=1.7159$。</p>
<h4 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h4><p>最後的輸出層，使用 Euclidean Radial Basis Function ( RBF ) 計算出每一個類別 (此例就是 0-9) 的數值</p>
<script type="math/tex; mode=display">
y_i=\sum\limits_{j}(x_j-w_{ij})^2</script><p>這個式子以及 $y_i$ 代表的意義是什麼呢 ?</p>
<p>在輸出層以前，我們輸入一張手寫圖片，最後會得到一個 84 維的向量，利用這 84 維向量跟各個類別的權重向量計算這兩者的歐式距離。</p>
<p>為什麼當初在 $F_6$ 層的輸出會取 84 個神經元 ?<br>因為我們要針對每一個類別給予一個標準權重值，好跟 $F_6$ 層的輸出來計算距離，那麼這個標準權重值就是從 ACSII 而來</p>
<p><img src="https://i.imgur.com/zG8PMM3.png" alt></p>
<p>這裡面每一個字母 / 數字 / 符號 都是 $7\times 12$ 的大小，每一個字符我們都可以化成一組 84 維的標準權重，其中每一維的值不是 +1 ，就是 -1。這樣的設計可以避免 $O,o,0$ 這種容易混淆的字符造成判別錯誤。</p>
<p>我們可以將各層視覺化出來，或許更能了解每一層的作用</p>
<p><img src="https://i.imgur.com/o49ic8B.png" alt></p>
<h3 id="C-Loss-Function"><a href="#C-Loss-Function" class="headerlink" title="C. Loss Function"></a>C. Loss Function</h3><p>一般來說我們的 Loss Function 會採用 Maximum Likelihood Estimation (MLE)，但在本論文中其實 MLE 等價於 Minimum MSE ( Mean Square Error )</p>
<script type="math/tex; mode=display">
E(W)=\displaystyle{\frac{1}{P}}\sum\limits_{p=1}^{P}y_{D_{p}}(Z^p,W)</script><p>$y_{D_{p}}$ 指的就是第 $p$ 筆資料輸入後所得的「正確類別」 RBF 值，所以訓練資料的 error 就是所有訓練資料所得「正確類別」 RBF 值之平均。( 從 RBF 的型態來看其實就是 mean square error )</p>
<p>但這樣的 Loss Function 有一些缺點 : </p>
<ol>
<li><p>RBF 的參數不可拿來訓練。倘若 RBF 的權重也可拿來訓練，會導致 RBF 權重會因不斷調整而趨於相等，而 $F_6$ 層的結果也會趨近於 RBF 權重，最後 RBF輸出均為 0。亦即不管輸入什麼資料，最後訓練出來的 RBF 輸出都會是 0 。</p>
</li>
<li><p>缺乏考慮各類別間的競爭關係。這樣的競爭關係我們可以用 Maximum a posteriori ( MAP , 最大後驗機率法 ) 來表示。假定一個樣本，我們希望他的預測可以接近真實的 label ，那我們從機率的角度來看就是要試著最大化它的後驗機率<sup><a href="#fn_註2" id="reffn_註2">註2</a></sup>。( 或是最小化正確類別的機率值取 $\log$ )。因此從這個方向我們可以修改一下我們的 Loss Function</p>
</li>
</ol>
<script type="math/tex; mode=display">
E(W)=\displaystyle{\frac{1}{P}}\sum\limits_{p=1}^{P}y_{D_{p}}(Z^p,W)+\log(e^{-j}+\sum\limits_{i}e^{-y_i(Z^p,W)})</script><p>從 $\sum\limits_{i}e^{-y_i(Z^p,W)}$ 這一項不難發現，若錯誤類別的 RBF 值越小，進行懲罰的就越多。如此一來，整個模型便能同時考量正確類別的誤差及其他類別的交互影響。</p>
<h2 id="後記"><a href="#後記" class="headerlink" title="後記"></a>後記</h2><p>這是一偏較早期的論文，所使用的方法其實在現在的 CNN 架構中很多都不被使用，舉例來說 $C_3$ 層使用的特殊特徵配對方式，由於現在的硬體效能都提升很多，現今已不再使用這樣的方式進行配對。各層所使用的 Sigmoid function 現在也大多被 ReLU 所取代。雖然如此，這篇論文的價值仍然不容被忽視，仍然可以提供完整圖像辨識的架構給讀者。</p>
<p>此篇論文的內容非常多，我也無法一次全部看完，目前就先以最重要的部分進行閱讀，待日後有時間再來將後面的部分補完。</p>
<h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol>
<li>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2323. DOI: 10.1109/5.726791 (論文<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">下載</a>)</li>
<li><a href="https://www.charleychai.com/blogs/2018/ai/NN/lenet.html" target="_blank" rel="noopener">LeNet-5详解与实现</a></li>
<li><a href="https://mattwang44.github.io/en/articles/PyTorchTP-LeNet/" target="_blank" rel="noopener">PyTorch Taipei 2018 week1: LeNet-5</a></li>
<li>論文筆記 —- <a href="https://hackmd.io/@K3QB5C-YSsyBr6dBBo6IkQ/rka5m35NX" target="_blank" rel="noopener">Gradient-Based Learning Applied to Document Recognition</a></li>
</ol>
<h2 id="註釋"><a href="#註釋" class="headerlink" title="註釋"></a>註釋</h2><p><sup><a href="#fn_註1" id="reffn_註1">註1</a></sup>:<br>在CNN上卷積操作其實就是 Slide + Inner Product，利用滑動的方式遍歷所有位置，並記錄下 kernel 與相對位置的內積值於 feature map 的相對位置上。</p>
<p><sup><a href="#fn_註2" id="reffn_註2">註2</a></sup>:<br>條件機率 : 在事件 $y$ 發生的前提下，事件 $x$ 發生的機率 $\boldsymbol{P}(x\mid y)$<br>後驗機率 : 事件 $x$ 事件發生後的反向條件機率 $\boldsymbol{P}(y\mid x)=\displaystyle{\frac{\boldsymbol{P}(x\mid y)\cdot\boldsymbol{P}(y)}{\boldsymbol{P}(x)}}$</p>

    </div>

    
    
    
        
      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>作者： </strong>Allen Tzeng</li>
  <li class="post-copyright-link">
    <strong>文章連結：</strong>
    <a href="https://allen108108.github.io/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/" title="[ 論文 ] Gradient-Based Learning Applied to Document Recognition">https://allen108108.github.io/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh_TW" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 許可協議。轉載請註明出處！</li>
</ul>
</div>

      

      <footer class="post-footer">

        
  <div class="post-widgets">
    <div class="wp_rating">
      <div id="wpac-rating"></div>
    </div>
  
  </div>

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/blog/2019/10/03/Anaconda 環境安裝 ( Win 10 )/" rel="next" title="Anaconda 環境安裝 ( Win 10 )">
                  <i class="fa fa-chevron-left"></i> Anaconda 環境安裝 ( Win 10 )
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/blog/2019/10/04/[論文] Imagenet Classification with Deep Convolutional Neural Networks/" rel="prev" title="[論文] Imagenet Classification with Deep Convolutional Neural Networks">
                  [論文] Imagenet Classification with Deep Convolutional Neural Networks <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    
  <div class="comments" id="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#論文摘要"><span class="nav-number">2.</span> <span class="nav-text">論文摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#I-Introduction"><span class="nav-number">3.</span> <span class="nav-text">I.  Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Learning-from-Data"><span class="nav-number">3.1.</span> <span class="nav-text">A. Learning from Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-Gradient-Based-Learning"><span class="nav-number">3.2.</span> <span class="nav-text">B. Gradient-Based Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C-Gradient-Back-Propagation"><span class="nav-number">3.3.</span> <span class="nav-text">C. Gradient Back-Propagation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#D-Learning-in-Real-Handwriting-Recognition-Systems"><span class="nav-number">3.4.</span> <span class="nav-text">D. Learning in Real Handwriting Recognition Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#E-Globally-Trainable-Systems"><span class="nav-number">3.5.</span> <span class="nav-text">E. Globally Trainable Systems</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#II-Convolutional-Neural-Network-for-Isolated-Character-Recognition"><span class="nav-number">4.</span> <span class="nav-text">II. Convolutional Neural Network for Isolated Character Recognition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Convolutional-Network"><span class="nav-number">4.1.</span> <span class="nav-text">A. Convolutional Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-LeNet-5"><span class="nav-number">4.2.</span> <span class="nav-text">B. LeNet-5</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Input"><span class="nav-number">4.2.1.</span> <span class="nav-text">Input</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C-1-卷積層"><span class="nav-number">4.2.2.</span> <span class="nav-text">$C_1$ (卷積層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#S-2-池化層"><span class="nav-number">4.2.3.</span> <span class="nav-text">$S_2$ (池化層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C-3-卷積層"><span class="nav-number">4.2.4.</span> <span class="nav-text">$C_3$ (卷積層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#S-4-池化層"><span class="nav-number">4.2.5.</span> <span class="nav-text">$S_4$ (池化層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C-5-卷積層"><span class="nav-number">4.2.6.</span> <span class="nav-text">$C_5$ (卷積層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#F-6-全連接層"><span class="nav-number">4.2.7.</span> <span class="nav-text">$F_6$ (全連接層)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Output"><span class="nav-number">4.2.8.</span> <span class="nav-text">Output</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C-Loss-Function"><span class="nav-number">4.3.</span> <span class="nav-text">C. Loss Function</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#後記"><span class="nav-number">5.</span> <span class="nav-text">後記</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#參考資料"><span class="nav-number">6.</span> <span class="nav-text">參考資料</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#註釋"><span class="nav-number">7.</span> <span class="nav-text">註釋</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/blog/images/allen.jpg"
      alt="Allen Tzeng">
  <p class="site-author-name" itemprop="name">Allen Tzeng</p>
  <div class="site-description" itemprop="description">Study about Mathematics , Programming and Data Science</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">111</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/blog/categories/">
          
        
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分類</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://allen108108.github.io/" title="Github page &rarr; https://allen108108.github.io/"><i class="fa fa-fw fa-github-alt"></i>Github page</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/allen108108" title="GitHub &rarr; https://github.com/allen108108" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:allen108108@hotmail.com" title="E-Mail &rarr; mailto:allen108108@hotmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://www.facebook.com/Mathpy-257929091666547/" title="FB Page &rarr; https://www.facebook.com/Mathpy-257929091666547/" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i>FB Page</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Allen Tzeng</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 強力驅動 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主題 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="訪客總數">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="總瀏覽次數">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='255, 80, 219' opacity='1' zIndex='-1' count='100' src="/blog/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/blog/lib/anime.min.js?v=3.1.0"></script>
  <script src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/blog/js/utils.js?v=7.4.0"></script><script src="/blog/js/motion.js?v=7.4.0"></script>
<script src="/blog/js/schemes/pisces.js?v=7.4.0"></script>

<script src="/blog/js/next-boot.js?v=7.4.0"></script>



  





  <script>
  if (CONFIG.page.isPost) {
    wpac_init = window.wpac_init || [];
    wpac_init.push({
      widget: 'Rating',
      id: 21351,
      el: 'wpac-rating',
      color: 'fc6423'
    });
    (function() {
      if ('WIDGETPACK_LOADED' in window) return;
      WIDGETPACK_LOADED = true;
      var mc = document.createElement('script');
      mc.type = 'text/javascript';
      mc.async = true;
      mc.src = '//embed.widgetpack.com/widget.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
    })();
  }
  </script>
















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://math-py.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  function disqus_config() {
    this.page.url = "https://allen108108.github.io/blog/2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/";
    this.page.identifier = "2019/10/04/[論文] Gradient-Based Learning Applied to Document Recognition/";
    this.page.title = '[ 論文 ] Gradient-Based Learning Applied to Document Recognition';};
  function loadComments() {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://math-py.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  }
    window.addEventListener('load', loadComments, false);
  
</script>

</body>
</html>
